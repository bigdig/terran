% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}
\usepackage{epstopdf}
\usepackage{algpseudocode}
\usepackage{algorithm}
\begin{document}

\title{An marginal density based hierarchical clustering algorithm for high dimensional continuous datasets
\titlenote{(Does NOT produce the permission block, copyright information nor page numbering). For use with ACM\_PROC\_ARTICLE-SP.CLS. Supported by ACM.}}
\subtitle{[Extended Abstract]
\titlenote{A full version of this paper is available as
\textit{Author's Guide to Preparing ACM SIG Proceedings Using
\LaTeX$2_\epsilon$\ and BibTeX} at
\texttt{www.acm.org/eaddress.htm}}}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Yutong Zhao\\
       \affaddr{Stanford University}\\
       \affaddr{318 Campus Drive}\\
       \affaddr{Stanford, California, 94305}\\
       \email{yutong.zhao@stanford.edu}
% 2nd. author
\alignauthor
???\\
      \affaddr{Stanford University}\\
       \affaddr{318 Campus Drive}\\
       \affaddr{Stanford, California, 94305}\\
       \email{}
% 3rd. author
\alignauthor ???\titlenote{This author is the
one who did all the really hard work.}\\
       \affaddr{The Th{\o}rv{\"a}ld Group}\\
       \affaddr{1 Th{\o}rv{\"a}ld Circle}\\
       \affaddr{Hekla, Iceland}\\
       \email{}
}
\maketitle
\begin{abstract}

To be done.

\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Theory}

\keywords{Clustering, \LaTeX, text tagging} % NOT required for Proceedings

\section{Introduction}

To be done.

\section{The Terran Algorithm}

Suppose we have $N$ points in $D$ dimensions. Our first objective is to find valleys in each marginalized dimension. These valleys guarantee that there is some distinct density cluster that can be used to partition the points. We can find these valleys using the expectation maximization algorithm.

\subsection{Estimating the Marginalized Density}
The algorithm begins by marginalizing each dimension, whose density is then estimated by fitting a 1D mixture model. The EM algorithm is initialized with an equally weighted $P$ component gaussian mixture model with the means randomly distributed in the range $[min_p, max_p]$, where $min_p$ and $max_p$ are the minimum and maximum coordinates in the set of points. During any iteration in the EM algorithm, if the weight of the $p$'th component is less than some tolerance $t$, then the $p$'th component is pruned. In addition, this process may repeat several times, returning the model with the highest likelihood. With a mixture model readily available, the resulting set of minima $M$ can be easily found. We then pick a subset of $M$ with a low probability cutoff $c$. These cutting points denote valleys which are then used to partition the domain. For non-periodic dimensions, at least one cut is needed to divide the domain into two connected partitions. For periodic dimensions (detailed later), at least two cuts are needed as periodic domains are connected at the boundary. In practice, $P=15$, $t=0.05$, $c=0.05$. In practice, these parameters are generally independent of the type and shape of data and need not be adjusted. 

\subsection{Hierarchical Cluster Tree}
 Given a set of partitions for each dimension, the algorithm loops over each point and assigns the points to a given $D$ dimensional bucket resulting in at most $N$ non-empty buckets. Each bucket in essence, becomes a child cluster own its own, whose dimensions each have a different marginalized density distribution from its parent. In Bayesian terms, a subset of the $D$ is essentially establishing a conditional, and it is not suprising that the marginalized distribution will change. In many cases, the dimensions in the child cluster has more valleys than the parent cluster. The process repeats until each dimension in each cluster can no longer be partitioned (which may result from either lack of minima or lack of points). The end results is a hierarchical cluster tree that can be searched by BFS.

\begin{algorithm}
\caption{Assign Points in a Cluster}\label{euclid}
\begin{algorithmic}[1]
\Procedure{AssignBucket}{point, partitions}
\State new bucket $b$ \Comment size dimensions
\For{each dimension $d$ in point}
\For{each divider $j$ in partitions}
\If{point[$d$] < partitions[$d$][$j$]}
\State $b$[$d$] $\leftarrow$ $j$
\State \textbf{break}
\EndIf
\If{isPeriodic($d$)}
\State $b$[$d$] $\leftarrow$ 0;
\Else
\State $b$[$d$] $\leftarrow$ $j$+1;
\EndIf
\EndFor
\EndFor
\State \textbf{return} $b$
\EndProcedure
\State

\Procedure{AssignAllPoints}{points}
\State new partitions \Comment size dimensions
\For{each dimension d}
\State partitions[d] $\leftarrow$ FindMinimaByEM(d)
\EndFor
\State new map $clusters$ \Comment bucket $\Rightarrow$ list of points
\For{each point $p$ in points}
\State bucket $\leftarrow$ AssignBucket(p, partitions)
\State clusters[bucket].push(p)
\EndFor
\State new list $assignment$ \Comment size dimensions
\State new int $clusterIndex$ $\leftarrow$ 0
\For{each key $k$ in in cluster}
\State new list $indices$ $\leftarrow$ cluster[$k$].value
\For{each index $i$ in $clusterPoints$}
\State pointId = index[i] 
\State assignment[pointId] $\leftarrow$  clusterIndex
\EndFor
\State $clusterIndex$++
\EndFor
\State \textbf{return} $assignment$
\EndProcedure
\end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Hierarchical Cluster Tree}\label{hct}
\begin{algorithmic}[1]
\Procedure{HierarchicalCluster}{points}
\State new Node $root$ \Comment class Node indices, list of children
\State $root$.indices $\leftarrow$ all points
\State create empty queue $Q$
\State $Q$.push(root)
\While{$Q$ not empty}
\State new $currentNode$ $\leftarrow$ $Q$.pop()
\State make new point using $currentNode$.indices
\State assignment $\leftarrow $AssignAllPoints(points)
\For{each group $g$ of points in assignment}
\State new Node $child$
\State $child$.indices $\leftarrow$ $g$
\State currentNode.children.add($child$)
\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Running Time}

Because EM is an iterative algorithm depending on convergence, it can be difficult to categorize the algorithm's running time strictly using big O notation. However, in nearly all tests, we observe that fitting an EM curve to a single dimension takes roughly $O(N_c D)$ time, where $N_c$ is the number of points in a cluster $c$ and $D$ is the number of dimensions. In addition, it is possible to subsample $N_c$ so long as we have sufficient sampling in the domain of interest. Thus each level in the cluster tree takes at most $O(N_C D)$ time to execute, where $N_C$ is total number points in all $C$ clusters on a level. In practice, the algorithm is linear with respect to the number of points and dimensions, with worst case being $O(K N D)$, where $K$ is the total number of ground truth cluster centers (and there by representing the maximum depth if the BFS Tree were somehow linearized. 

Currently, in practice, the algorithm is bottlenecked by the step that finds steep valleys in each dimension. However, because each dimension can be fit independently, the algorithm can be linearly parallelized up to the number of dimensions. 

\section{Experiments}

We begin by comparing TERRAN against several other popular clustering algorithms: DBSCAN, Spectral Clustering, Mean Shift, and K Means in 2D. These popular clustering algorithms are highly dependent on the choice of parameters and a distance metric defined between two points. The $k$-based clustering algorithms heavily rely on the number of centers to be specified a priori. Mean shift and DBSCAN do not require the number of clusters to known a priori, instead opting for density parameters and are superior in their ability to detect non-convex shapes. Quite often, these freebies are not available, especially in higher dimensions. The effect is that these parameter sensitive algorithms can easily result in oversplitting and/or undersplitting of clusters. 

In contrast, TERRAN has only one cutting parameter that is generally insensitive to the type of data, and will not oversplit clusters. This is shown in the double moon, double circle, and uniform example distributions. In addition, TERRAN is unique in that it is essentially metricless, which shows its utility in high dimensional datasets as it avoids computing $D$ dimension metrics, thereby avoiding the curse of dimensionality.

In higher dimensions, we generated two datasets in 100 dimensions. The first dataset comprised of 2 clusters generated using gaussians where only one dimension had two modes upon marginalization. The second dataset comprised of 20 different clusters, with each dimension varying between three to five different modes upon marginalization. The results of the fit scored using the Adjusted Rand Index, which uses the ground truth labels to score the predicted labels. Guessing the density parameters for DBSCAN proved difficult, as the algorithm was not able to establish core points. In the 20 cluster test case, spectral clustering had trouble even if the number of clusters were given a priori. Surprisingly enough, the KMeans algorithm performed exceptionally well if the number of centers were given a priori, but this is presumably due to the fact we used convex gaussian-like clusters to start with, and Voronoization of high dimensional space exponentially increases the amount coverage for each centroid (SW: comment?). The Terran algorithm scored extremely high without any parameter tuning. 

However, the algorithm generally depends on existence of these steep valleys in the marginalized densities. In other words, it assumes that the underlying clusters are somewhat linearly separable by axes-aligned lines. Otherwise the algorithm will undersplit the clusters. In addition, the EM component assumes that marginalized densities can indeed be fit using some mixture model. We note that an alternative method to locate said minima is to form an $N$-component GMM using Gaussian Kernel Density Estimation, however, estimation of all the minima via bisection can become prohibitively expensive for large $N$. In addition, Kernel methods suffer from the need to accurately establish a good bandwidth parameter, as too small of bandwidth will over estimate the number of valleys, and too big a bandwidth will underestimate the number of valleys. 

\begin{table*}
\centering
\caption{Clustering in 100 Dimensions}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|l|} \hline
DB e=1.0 & DB e=2.0 & S k=2 & S k=17 & S k=20 & S k=23 & KM k=2 & KM k=17 & KM k=20 & KM k=23 & Terran \\ \hline
N/A & N/A & 0.01 & 0.792 & 0.286 & 0.250 & 0.073 & 0.862 & 1.0 & 0.959 & 0.996\\ \hline
N/A & N/A & 0.996 & 0.065 & 0.049 & 0.338 & 1.0 & 0.534 & 0.530 & 0.524 & 0.992\\ \hline \end{tabular}
\end{table*}
% end the environment with {table*}, NOTE not {table}!

\section{Clustering in Periodic Spaces}

For many applications, such as clustering and density estimation of large molecules (eg. proteins), a transformation to internal coordinate space comprised of periodic dimensions (such as torsion angles and bond angles), and nonperiodic dimensions (such as bond lengths), results in a natural dimensionality reduction. Surprisingly, this tranformation often results in linearly seperable degrees of freedom in many physical systems. However, this also implies a need to come with a robust periodic basis. Here, we introduce the periodic gaussian, also known as wrapped gaussians in other literature, and demonstrate the use of the EM algorithm with this basis

\subsection{Periodic Gaussian}
Recall the definition of the gaussian distribution,
\begin{equation}
g(x; u,s) = \dfrac{1}{s\sqrt{2\pi}} \exp\left(-\dfrac{1}{2} \left(\dfrac{x-u}{s}\right)^2\right)
\end{equation}
The periodic gaussian (otherwise known as a wrapped gaussian) is defined on some periodic manifold \textbf{$M$}:
\begin{equation}
g_p(x; u,s) = \sum_{r=-\infty}^{\infty} g(x; u+rD, s)
\end{equation}
where \textbf{$D$} is the period of \textbf{$M$}. The periodic gaussian has the same normalization constant as the standard gaussian, it is continuous everywhere in the domain, and is relatively cheap to evaluate despite the infinite summation due to the rapid exponentatial decay of the gaussian. In practice, the summation is bound between a very small range. The periodic gaussian is very similar to the von Mises distribution, but it has the advantage in that it can be easily defined for periods other than \textbf{$2\pi$}. The periodic gaussian has the derivative:
\begin{equation}
\dfrac{\partial g_p(x;u,s)}{\partial x} = \dfrac{1}{s^2} \sum_{r=-\infty}^{\infty} (u-x+rD) g(x; u+rD, s)
\end{equation}

Similar to standard gaussian, it is possible to define a \textbf{$K$} component periodic gaussian mixture given some set of parameters \textbf{$\theta$}:
\begin{equation}
g_{pm}(x;\theta) = \sum_{k=1}^{K} p_k g_p(x; u_k, s_k)
\end{equation}
A periodic gaussian mixture has at most \textbf{$K$} minima, whereas a gaussian mixture has at most \textbf{$K+1$} minima. The periodic gaussian mixture has the derivative:
\begin{equation}
\dfrac{\partial g_{pm}(x; \theta)}{\partial x} =  \sum_{k=1}^{K} p_k \dfrac{\partial g_p(x; u_k, s_k)}{\partial x}
\end{equation}

In practice, these derivatives behave very well when used to find minima and maxima of the mixture models.

\subsection{EM on Periodic Gaussians}

A natural tendency of gaussians is to form mixture models in order to fit data. In general, EM for gaussian mixture models is very well behaved and studied, and it makes natural sense derive equations for EM to accommodate periodic gaussians. We first define the log likelihood function for periodic gaussians for some 1D dataset \textbf{$X$} of size \textbf{$N$} with parameters \textbf{$\theta$} for the mixture model,
\begin{equation}
\lambda(X; \theta) = \sum_{n=1}^{N} \log \sum_{k=1}^{K} p_k g_p(x;u_k, s_k)
\end{equation}
In addition, define the membership probability expressed as the condititional probability,
\begin{equation}
p(k|n) = \dfrac{p_k g_p(x_n; u_k, s_k)}{\sum\limits^{K}_{m=1} p_m g_p(x_n; u_k, s_k)}
\end{equation}
it can then be shown that
\begin{equation}
\sum_{k=1}^{K} p(k|n) = 1
\end{equation}
The next step in EM is to derive the derivatives of the likelihood with respect to the parameters, for notational convenience, define
\begin{align}
g & \equiv g(x_n; u_k, s_k) \\
g_p & \equiv g_p(x_n; u_k, s_k)
\end{align}
and,
\begin{align}
\dfrac{\partial \lambda}{\partial p_k} & = p_k - \dfrac{1}{N} \sum\limits^{N}_{n=1}p(k|n) \\
\dfrac{\partial \lambda}{\partial u_k} &= \dfrac{1}{s_k^2} \sum_{n=1}^{N}p(k|n) \left(x_n - u_k - D \frac{\sum\limits^{\infty}_{r=-\infty} rg}{\sum\limits^{\infty}_{r=-\infty}g} \right) \\
\begin{split}
\dfrac{\partial \lambda}{\partial s_k} & = \sum\limits^{N}_{n=1}p(k|n) \left(-\dfrac{1}{s_k} + \dfrac{(x_n-u_k)^2}{s_k^3}\right. \\
&\left. -\dfrac{2(x_n-u_k)D\sum\limits^{\infty}_{r=-\infty}rg}{s_k^3 \sum\limits^{\infty}_{r=-\infty}g} + \dfrac{D^2 \sum\limits^{\infty}_{r=-\infty}r^2g}{s_k^3 \sum\limits^{\infty}_{r=-\infty}g} \right)
\end{split}
\end{align}
What we are interested in is finding the values of \textbf{$p_k, u_k, s_k$} such that the likelihood attains a local maxima. This is equivalent to finding the roots of the above equations. Solving for \(p_k\) is trivial, but \(u_k\) and \(s_k\) are a bit tricky.  The two latter derivatives are first simplified by multiplying \(s_k^2\) and \(s_k^3\) respectively. We first note that \(\partial \lambda \backslash \partial u_k \) is periodic with respect to \(u_k\), and has exactly two roots corresponding to a  maxium  and minimum in the likelihood function. The two points that bracket the maximum can be found easily by sampling the domain, and the subsequent maximum can be found by means of bisection. For \(\partial \lambda \backslash \partial s_k\), there is exactly one root in the interval \((0, D]\) for all practical purposes, which can be then isolated by bisection once again.

VJ, SW: Not sure what to do here, introduce another set of data? Large protein data? (Don't think CS conf will care as much)

\section{Future Direction}

There are several ways to expand this algorithm to make it more robust. The first major revamp is to introduce better density estimators such as gaussian kernel density estimators. In addition, algorithmic development rapid determination of the curves for the minima of 2D periodic and non periodic gaussian mixture models would take make the algorithm significantly more robust for higher dimensions. Theoretically speaking, it should be possible to derive a level set formulation for 2D mixture models (either via EM or Kernel Density Estimation) to repeatedly partition the points, or perhaps using more classical methods so long as it guarantees that clusters are not oversplit. 

VJ, SW: I want to emphasis that the key theoretical take home message from this paper is:

1) It's critical that clustering algorithms do not oversplit because:
2) Applying a conditional prior allows us to deconvolute the marginalized density distributions so as long as we can guarantee 1). There's nothing specific about us having to marginalize to 1 dimension, we only did it because it was easy! We could marginalize to 2 dimensions as well (eg. x,y,z,w,t,a,b -> marginalized to a 2D (x,y) given all possible z,w,t,a,b) so long as we can guarantee the clusters we find in two dimensions obey 1). We can probably even use DBSCAN etc. to deal with this in 2D. Whenever we can guarantee a good split, we deconvolute the data!

I think this is by far the most valuable and novel part of the paper. 

\section{NOT USEFUL STUFF BELOW THIS}

\subsection{Math Equations}
You may want to display math equations in three distinct styles:
inline, numbered or non-numbered display.  Each of
the three are discussed in the next sections.

To do last
This paper provides a sample of a \LaTeX\ document which conforms to
the formatting guidelines for ACM SIG Proceedings.
It complements the document \textit{Author's Guide to Preparing
ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and Bib\TeX}. This
source file has been written with the intention of being
compiled under \LaTeX$2_\epsilon$\ and BibTeX.

The developers have tried to include every imaginable sort
of ``bells and whistles", such as a subtitle, footnotes on
title, subtitle and authors, as well as in the text, and
every optional component (e.g. Acknowledgments, Additional
Authors, Appendices), not to mention examples of
equations, theorems, tables and figures.

To make best use of this sample document, run it through \LaTeX\
and BibTeX, and compare this source code with the printed
output produced by the dvi file.


The \textit{proceedings} are the records of a conference.
ACM seeks to give these conference by-products a uniform,
high-quality appearance.  To do this, ACM has some rigid
requirements for the format of the proceedings documents: there
is a specified format (balanced  double columns), a specified
set of fonts (Arial or Helvetica and Times Roman) in
certain specified sizes (for instance, 9 point for body copy),
a specified live area (18 $\times$ 23.5 cm [7" $\times$ 9.25"]) centered on
the page, specified size of margins (1.9 cm [0.75"]) top, (2.54 cm [1"]) bottom
and (1.9 cm [.75"]) left and right; specified column width
(8.45 cm [3.33"]) and gutter size (.83 cm [.33"]).

The good news is, with only a handful of manual
settings\footnote{Two of these, the {\texttt{\char'134 numberofauthors}}
and {\texttt{\char'134 alignauthor}} commands, you have
already used; another, {\texttt{\char'134 balancecolumns}}, will
be used in your very last run of \LaTeX\ to ensure
balanced column heights on the last page.}, the \LaTeX\ document
class file handles all of this for you.

The remainder of this document is concerned with showing, in
the context of an ``actual'' document, the \LaTeX\ commands
specifically available for denoting the structure of a
proceedings paper, rather than with giving rigorous descriptions
or explanations of such commands.

\subsubsection{Inline (In-text) Equations}
A formula that appears in the running text is called an
inline or in-text formula.  It is produced by the
\textbf{math} environment, which can be
invoked with the usual \texttt{{\char'134}begin. . .{\char'134}end}
construction or with the short form \texttt{\$. . .\$}. You
can use any of the symbols and structures,
from $\alpha$ to $\omega$, available in
\LaTeX\cite{Lamport:LaTeX}; this section will simply show a
few examples of in-text equations in context. Notice how
this equation: \begin{math}\lim_{n\rightarrow \infty}x=0\end{math},
set here in in-line math style, looks slightly different when
set in display style.  (See next section).


The resulting clusters 

Typically, the body of a paper is organized
into a hierarchical structure, with numbered or unnumbered
headings for sections, subsections, sub-subsections, and even
smaller sections.  The command \texttt{{\char'134}section} that
precedes this paragraph is part of such a
hierarchy.\footnote{This is the second footnote.  It
starts a series of three footnotes that add nothing
informational, but just give an idea of how footnotes work
and look. It is a wordy one, just so you see
how a longish one plays out.} \LaTeX\ handles the numbering
and placement of these headings for you, when you use
the appropriate heading commands around the titles
of the headings.  If you want a sub-subsection or
smaller part to be unnumbered in your output, simply append an
asterisk to the command name.  Examples of both
numbered and unnumbered headings will appear throughout the
balance of this sample document.

Because the entire article is contained in
the \textbf{document} environment, you can indicate the
start of a new paragraph with a blank line in your
input file; that is why this sentence forms a separate paragraph.

\subsubsection{Display Equations}
A numbered display equation -- one set off by vertical space
from the text and centered horizontally -- is produced
by the \textbf{equation} environment. An unnumbered display
equation is produced by the \textbf{displaymath} environment.

Again, in either environment, you can use any of the symbols
and structures available in \LaTeX; this section will just
give a couple of examples of display equations in context.
First, consider the equation, shown as an inline equation above:
\begin{equation}\lim_{n\rightarrow \infty}x=0\end{equation}
Notice how it is formatted somewhat differently in
the \textbf{displaymath}
environment.  Now, we'll enter an unnumbered equation:
\begin{displaymath}\sum_{i=0}^{\infty} x + 1\end{displaymath}
and follow it with another numbered equation:
\begin{equation}\sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f\end{equation}
just to demonstrate \LaTeX's able handling of numbering.

\subsection{Citations}
Citations to articles \cite{bowman:reasoning, clark:pct, braams:babel, herlihy:methodology},
conference
proceedings \cite{clark:pct} or books \cite{salas:calculus, Lamport:LaTeX} listed
in the Bibliography section of your
article will occur throughout the text of your article.
You should use BibTeX to automatically produce this bibliography;
you simply need to insert one of several citation commands with
a key of the item cited in the proper location in
the \texttt{.tex} file \cite{Lamport:LaTeX}.
The key is a short reference you invent to uniquely
identify each work; in this sample document, the key is
the first author's surname and a
word from the title.  This identifying key is included
with each item in the \texttt{.bib} file for your article.

The details of the construction of the \texttt{.bib} file
are beyond the scope of this sample document, but more
information can be found in the \textit{Author's Guide},
and exhaustive details in the \textit{\LaTeX\ User's
Guide}\cite{Lamport:LaTeX}.

This article shows only the plainest form
of the citation command, using \texttt{{\char'134}cite}.
This is what is stipulated in the SIGS style specifications.
No other citation format is endorsed.

\subsection{Tables}
Because tables cannot be split across pages, the best
placement for them is typically the top of the page
nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and
the table caption.  The contents of the table itself must go
in the \textbf{tabular} environment, to
be aligned properly in rows and columns, with the desired
horizontal and vertical rules.  Again, detailed instructions
on \textbf{tabular} material
is found in the \textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table 1 is included in the input file; compare the
placement of the table here with the table in the printed
dvi output of this document.

\begin{table}
\centering
\caption{Frequency of Special Characters}
\begin{tabular}{|c|c|l|} \hline
Non-English or Math&Frequency&Comments\\ \hline
\O & 1 in 1,000& For Swedish names\\ \hline
$\pi$ & 1 in 5& Common in math\\ \hline
\$ & 4 in 5 & Used in business\\ \hline
$\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
\hline\end{tabular}
\end{table}

To set a wider table, which takes up the whole width of
the page's live area, use the environment
\textbf{table*} to enclose the table's contents and
the table caption.  As with a single-column table, this wide
table will ``float" to a location deemed more desirable.
Immediately following this sentence is the point at which
Table 2 is included in the input file; again, it is
instructive to compare the placement of the
table here with the table in the printed dvi
output of this document.

\subsection{Figures}
Like tables, figures cannot be split across pages; the
best placement for them
is typically the top or the bottom of the page nearest
their initial cite.  To ensure this proper ``floating'' placement
of figures, use the environment
\textbf{figure} to enclose the figure and its caption.

This sample document contains examples of \textbf{.eps}
and \textbf{.ps} files to be displayable with \LaTeX.  More
details on each of these is found in the \textit{Author's Guide}.

%
%\begin{figure}
%\centering
%\epsfig{file=fly.eps}
%\caption{A sample black and white graphic (.eps format).}
%\end{figure}
%
%\begin{figure}
%\centering
%\epsfig{file=fly.eps, height=1in, width=1in}
%\caption{A sample black and white graphic (.eps format)
%that has been resized with the \texttt{epsfig} command.}
%\end{figure}


As was the case with tables, you may want a figure
that spans two columns.  To do this, and still to
ensure proper ``floating'' placement of tables, use the environment
\textbf{figure*} to enclose the figure and its caption.

Note that either {\textbf{.ps}} or {\textbf{.eps}} formats are
used; use
the \texttt{{\char'134}epsfig} or \texttt{{\char'134}psfig}
commands as appropriate for the different file types.

\subsection{Theorem-like Constructs}
Other common constructs that may occur in your article are
the forms for logical constructs like theorems, axioms,
corollaries and proofs.  There are
two forms, one produced by the
command \texttt{{\char'134}newtheorem} and the
other by the command \texttt{{\char'134}newdef}; perhaps
the clearest and easiest way to distinguish them is
to compare the two in the output of this sample document:

This uses the \textbf{theorem} environment, created by
the\linebreak\texttt{{\char'134}newtheorem} command:
\newtheorem{theorem}{Theorem}
\begin{theorem}
Let $f$ be continuous on $[a,b]$.  If $G$ is
an antiderivative for $f$ on $[a,b]$, then
\begin{displaymath}\int^b_af(t)dt = G(b) - G(a).\end{displaymath}
\end{theorem}

The other uses the \textbf{definition} environment, created
by the \texttt{{\char'134}newdef} command:
\newdef{definition}{Definition}
\begin{definition}
If $z$ is irrational, then by $e^z$ we mean the
unique number which has
logarithm $z$: \begin{displaymath}{\log e^z = z}\end{displaymath}
\end{definition}

Two lists of constructs that use one of these
forms is given in the
\textit{Author's  Guidelines}.

\begin{figure*}
\centering
%\epsfig{file=flies.eps}
\caption{A sample black and white graphic (.eps format)
that needs to span two columns of text.}
\end{figure*}
and don't forget to end the environment with
{figure*}, not {figure}!
 
There is one other similar construct environment, which is
already set up
for you; i.e. you must \textit{not} use
a \texttt{{\char'134}newdef} command to
create it: the \textbf{proof} environment.  Here
is a example of its use:
\begin{proof}
Suppose on the contrary there exists a real number $L$ such that
\begin{displaymath}
\lim_{x\rightarrow\infty} \frac{f(x)}{g(x)} = L.
\end{displaymath}
Then
\begin{displaymath}
l=\lim_{x\rightarrow c} f(x)
= \lim_{x\rightarrow c}
\left[ g{x} \cdot \frac{f(x)}{g(x)} \right ]
= \lim_{x\rightarrow c} g(x) \cdot \lim_{x\rightarrow c}
\frac{f(x)}{g(x)} = 0\cdot L = 0,
\end{displaymath}
which contradicts our assumption that $l\neq 0$.
\end{proof}

Complete rules about using these environments and using the
two different creation commands are in the
\textit{Author's Guide}; please consult it for more
detailed instructions.  If you need to use another construct,
not listed therein, which you want to have the same
formatting as the Theorem
or the Definition\cite{salas:calculus} shown above,
use the \texttt{{\char'134}newtheorem} or the
\texttt{{\char'134}newdef} command,
respectively, to create it.

\subsection*{A {\secit Caveat} for the \TeX\ Expert}
Because you have just been given permission to
use the \texttt{{\char'134}newdef} command to create a
new form, you might think you can
use \TeX's \texttt{{\char'134}def} to create a
new command: \textit{Please refrain from doing this!}
Remember that your \LaTeX\ source code is primarily intended
to create camera-ready copy, but may be converted
to other forms -- e.g. HTML. If you inadvertently omit
some or all of the \texttt{{\char'134}def}s recompilation will
be, to say the least, problematic.

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Headings in Appendices}
The rules about hierarchical headings discussed above for
the body of the article are different in the appendices.
In the \textbf{appendix} environment, the command
\textbf{section} is used to
indicate the start of each Appendix, with alphabetic order
designation (i.e. the first is A, the second B, etc.) and
a title (if you include one).  So, if you need
hierarchical structure
\textit{within} an Appendix, start with \textbf{subsection} as the
highest level. Here is an outline of the body of this
document in Appendix-appropriate form:
\subsection{Introduction}
\subsection{The Body of the Paper}
\subsubsection{Type Changes and  Special Characters}
\subsubsection{Math Equations}
\paragraph{Inline (In-text) Equations}
\paragraph{Display Equations}
\subsubsection{Citations}
\subsubsection{Tables}
\subsubsection{Figures}
\subsubsection{Theorem-like Constructs}
\subsubsection*{A Caveat for the \TeX\ Expert}
\subsection{Conclusions}
\subsection{Acknowledgments}
\subsection{Additional Authors}
This section is inserted by \LaTeX; you do not insert it.
You just add the names and information in the
\texttt{{\char'134}additionalauthors} command at the start
of the document.
\subsection{References}
Generated by bibtex from your ~.bib file.  Run latex,
then bibtex, then latex twice (to resolve references)
to create the ~.bbl file.  Insert that ~.bbl file into
the .tex source file and comment out
the command \texttt{{\char'134}thebibliography}.
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
\section{More Help for the Hardy}
The acm\_proc\_article-sp document class file itself is chock-full of succinct
and helpful comments.  If you consider yourself a moderately
experienced to expert user of \LaTeX, you may find reading
it useful but please remember not to change it.
\balancecolumns
% That's all folks!
\end{document}
